---
title: "SIRTD Data Generating Processes"
author:
  - "Breck Baldwin"
  - "Jose Storopoli"
  - "Conor Rosato"
date:  '`r format(Sys.Date(), "%B %d, %Y")`'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, comment = NA, include = TRUE)
set.seed(4857)
```

# Introduction

This page contains data generating programs for a common class of epidemiological models derived from compartments for the states (S) susceptible, (I) infectious and (R) for recovered --SIR models. This page/code adds compartments for (T) terminal and (D) dead counts useful for the grim task of distinguishing the dead from recovered. There is additionally data generated for tweets but that exists in parallel with the core SIRTD model.

For more explanation about SIR models see [https://mc-stan.org/users/documentation/case-studies/boarding_school_case_study.html](https://mc-stan.org/users/documentation/case-studies/boarding_school_case_study.html) which we found to be a good explanation as well as an excellent introduction to Bayesian approaches using Stan. This is the model used to fit this data, there is a model reproduction check list at [https://codatmo.github.io/Simple_SIR/](https://codatmo.github.io/Simple_SIR/).

# Navigation

This Rmarkdown page exists as part of the [CoDatMo](https://codatmo.github.io/) project. The repo containing this page is at [https://github.com/codatmo/dataGeneratingProcess1/](https://github.com/codatmo/dataGeneratingProcess/) as 'runEval.Rmd' and rendered as 'runEval.html'.

# Data Generating Process

The data generating process simulates a fixed population at the individual level on a daily basis. Larger or smaller uniform units could be used. 

<!--At a pseudo code level the algorithm is:

```
nPop = 1000 # population size
nPatientZero = 10 # how many start infected
nDailyContacts = 10 # number of daily contacts per day for infected
betaDailyInfectionRates[nDays] = list of infection rate for each day--can vary
gammaResolvedDailyRate = rate moving from 'i' to 'r' or 't'
dailyTweetRateInfected = rate of tweets per person that is 'i'
meanDaysToDeath = mean of how many days does it take from 't' to 'd'
Create dayState[nPop] list of all people with state = 's' for susceptible

Patient zeros: set nPatientZero number of dayState list to 'i' for infected


tweets[nDay] = count of tweets per day


for (day in numberOfDays) {
  Copy dayState to nextDayState
  for (person in 1 to nPop) { # infections
    if (dayState[person] equals 'i') { # infecting others
      for (otherPerson in sample(numberDailyContacts, nPop))
        chanceInfection = betaDailyInfectionRates[day]/numberDailyContacts
          if (randomChance(person, chanceInfection) == infected and
              dayState[otherPerson] equals 's') {
             nextDayState[otherPerson] = 'i'
          }
    }
    if (dayState[person] equals 'i') { # recovery or death
      if (randomChance(person, gammaResolvedDailyRate) == resolved) {
         if (randomChoice(person, deathRate) == died) {
            nextDayState[person] = 't' #terminally ill
         }
         else {
            nextDayState[person] = 'r' # recovered, will not die
         }
      }
    }
    if (dayState[person] equals 'i') { # do they tweet while infected
      if (randomChance(person, tweetDailyRateInfected) == tweets) {
         tweetCountForDay[day] = tweetCountForDay[day] + 1
      }
    }
    if (dayState[person] equals 't') { # does a 't' -> 'd'
      if (randomChance(person, meanDaysToDeath) == death) {
          nextDayState[person] = 'd'
      }
    }
   dayState = nextDayState # overwrite the current day with the day we just created
}
```
The `randomChance()` function stands in place of many functions like the Bernoulli distribution. But there are many candidates, the source below details the actual choices.

Actual code below
-->


```{r echo=TRUE }
cat(paste(readLines(here::here("R","SIRTDsim.R")), "\n"))
```

# Running simulation and fitting a model

Below we go over how to setup and run the simulation code that generates data and runs experiments. The code is in `R\runEval.R` and the code below is pulled dynamically from the code so it will always be up to date every time this document is generated. 

```{r echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, results='hide'}
source(here::here('R','runEval.R'))
```


```{r echo=TRUE}

pull_section <- function(section, file) {
  print = FALSE
  return_string = ''
  for (line in readLines(file)) {
    if (line == section) {
      print = !print
    }
    if (print) {
      return_string = paste0(return_string, line, '\n')
    }
  }
  return(return_string)
}

cat(pull_section('# section 1', here::here('R','runEval.R')))

```
Above the `template_df` is initialized with column names and global parmeters, `n_days` and  `n_pop`. The simulation will populate the data columns, actual data may only populate some of the columns, e.g., `template_df$d` and `templte_df$tweets` in the case of the current Brazil data. Printing the data frame: 
```{r}
print(template_df)
```

### Adding simulation parameters

The parameterization for the simulation is next with deep copies being made of the `template_df` for the number of simulation configurations being created with `n_runs`.

```{r}
cat(pull_section('# section 2', here::here('R','runEval.R')))
```
Some parameters have one value across runs, others are a separate draw. The `sim_run_id` will be the same for subsequent copies of that particular draw, this becomes important when multiple modeling options are tried on the same simulated data. 


## Running the simulation

The simulation is run next with parameters defined above:
```{r}
cat(pull_section('# section 3', here::here('R','runEval.R')))
```
The simulation is run, setting `print` to `TRUE` gives day by day accounting of the simulation. We now have a complete simulation run per row of the `SIRTD_sim_df`. Next we add modeling configurations. 

```{r} 
print(SIRTD_sim_df)
```

## Running non-simulated data

It is possible to run data in this setup from non-simulated sources. An example will be eventually supplied. 

## Configuring modeling

Now we add the ways to configure modeling parameters. Since the number of simulations run will be copied per model setup there will be model setups X simulation setups rows in in the resulting data frame. 

```{r}
cat(pull_section('# section 4', here::here('R','runEval.R')))
```
Note that the `description` value is appended so it is possible to track variations. In this example the use of tweets to inform the model is varied. The `run_df` is created from the two model setups and then the the `ode_solver` and `compute_liklihood` parameters are set that will span all the model/sim configurations.

## Running models

Each row of `run_df` is a complete specification of data and model configuration. The code simply iterates over each row, fits it with the appropriate model/model configuration and adds the results of computing how many simulated days data for tweets and deaths are i the .2 to .8 center interval of the samples. See `R/util.R` for the implementation of `countPredictionsInQuantile`.

```{r}
cat(pull_section('# section 5', here::here('R','runEval.R')))
```

## Presenting results

At this point results will likely get more idiosyncratic to experiment needs. Below we present the filled data frame with the relevant summary columns.

```{r}
  cat(pull_section('# section 6', here::here('R','runEval.R')))
```
```{r echo=FALSE}
print(run_df[,summary_cols])
```

There are many more result views available that we will eventually integrate into this document. They include:

* Comparison of a ODE predictions to simulation compartments for appropriate models. 
* Using ribbon plots to graph varying sampling intervals
* Time series analyis, e.g., what happens with simulations that only provide the first interval of data to the models? 
